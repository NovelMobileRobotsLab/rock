{
    "algorithm": {
        "clip_param": 0.2,
        "desired_kl": 0.01,
        "entropy_coef": 0.01,
        "gamma": 0.999,
        "lam": 0.99,
        "learning_rate": 0.0003,
        "max_grad_norm": 1.0,
        "num_learning_epochs": 5,
        "num_mini_batches": 2,
        "schedule": "adaptive",
        "use_clipped_value_loss": true,
        "value_loss_coef": 0.1
    },
    "init_member_classes": {},
    "policy": {
        "activation": "elu",
        "actor_hidden_dims": [
            128,
            128,
            128,
            128
        ],
        "critic_hidden_dims": [
            128,
            128,
            128,
            128
        ],
        "init_noise_std": 1.0
    },
    "runner": {
        "algorithm_class_name": "PPO",
        "checkpoint": -1,
        "experiment_name": "balo1_2025-02-25_11-48-05",
        "load_run": -1,
        "log_interval": 1,
        "num_steps_per_env": 240,
        "policy_class_name": "ActorCritic",
        "record_interval": -1,
        "resume": false,
        "resume_path": null,
        "run_name": "",
        "runner_class_name": "runner_class_name",
        "save_interval": 50
    },
    "runner_class_name": "OnPolicyRunner",
    "seed": 1
}